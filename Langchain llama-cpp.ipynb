{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c4103c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a08fbc",
   "metadata": {},
   "source": [
    "## Llama.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4acb85bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c300df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# Verbose is required to pass to the callback manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41037391",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce RTX 3060\n",
      "llama.cpp: loading model from ./models/wizardLM-13B-Uncensored.ggmlv3.q5_1.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 9 (mostly Q5_1)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  = 2165.28 MB (+ 1608.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x 1 MB = 512 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 40 repeating layers to GPU\n",
      "llama_model_load_internal: offloading non-repeating layers to GPU\n",
      "llama_model_load_internal: offloaded 41/43 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 9706 MB\n",
      "....................................................................................................\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "n_gpu_layers = 41 # Change this value based on your model and your GPU VRAM pool.\n",
    "n_batch = 512 # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "\n",
    "model_path={\n",
    "    \"wizard-vicuna-13B-q5_1\" : \"./models/wizard-vicuna-13B.ggmlv3.q5_1.bin\",\n",
    "    \"wizardLM-13B.q5_1\" : \"./models/wizardLM-13B-Uncensored.ggmlv3.q5_1.bin\",\n",
    "    \"wizardLM-13B.q4_1\" : \"./models/wizardLM-13B-Uncensored.ggmlv3.q4_1.bin\",\n",
    "    \n",
    "}\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "local_llm = LlamaCpp(\n",
    "    model_path=model_path[\"wizardLM-13B.q5_1\"],\n",
    "    n_gpu_layers=n_gpu_layers, n_batch=n_batch,\n",
    "    callback_manager=None, \n",
    "    verbose=True,\n",
    "    n_ctx=2048,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28811084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf93a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2159739359.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"wizardLM-7B-HF\" = \"TheBloke/wizardLM-7B-HF\",\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_name = {\n",
    "    \"wizardLM-7B-HF\" = \"TheBloke/wizardLM-7B-HF\",\n",
    "    \"wizard-vicuna-13B-GPTQ\" = \"TheBloke/wizard-vicuna-13B-GPTQ\",\n",
    "    \"Wizard-Vicuna-13B-Uncensored\" = \"ehartford/Wizard-Vicuna-13B-Uncensored\",\n",
    "}\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(model_name[\"wizardLM-7B-HF\"],\n",
    "                                              load_in_8bit=True,\n",
    "                                              device_map='auto',\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4513c37b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f6887a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import JSONLoader\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "file_path='./data/faq_dataset.json'\n",
    "data = json.loads(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0cd9f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path='./data/faq_dataset.json',\n",
    "    jq_schema='.questions[] | \"Question: \\(.question) \\n Answer: \\(.answer)\\n\"')\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197de46f",
   "metadata": {},
   "source": [
    "## Prepare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fea61aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7cadac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings, HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model_attr = {\n",
    "    \"all-MiniLM-L6-v2\" : { \"name\" : \"sentence-transformers/all-MiniLM-L6-v2\" , 'kwargs' : {'device': 'cpu'} },\n",
    "    \"instructor-base\" : { \"name\" : \"hkunlp/instructor-base\" , 'kwargs' : {\"device\": \"cpu\"} },\n",
    "    \"instructor-xl\" : { \"name\" : \"hkunlp/instructor-xl\" , 'kwargs' : {'device': 'cuda'} },\n",
    "}\n",
    "\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "instructor_embeddings =  HuggingFaceEmbeddings(model_name=embedding_model_attr[embedding_model_name]['name'], \n",
    "                                               model_kwargs=embedding_model_attr[embedding_model_name]['kwargs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3575dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Here is the nmew embeddings being used\n",
    "embedding = instructor_embeddings\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=data, \n",
    "                                 embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bf74d15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\\n\", metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 1}),\n",
       "  0.6770732998847961),\n",
       " (Document(page_content='Question: Can I order without creating an account? \\n Answer: Yes, you can place an order as a guest without creating an account. However, creating an account offers benefits such as order tracking and easier future purchases.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 17}),\n",
       "  1.2404284477233887),\n",
       " (Document(page_content='Question: Do you have a loyalty program? \\n Answer: Yes, we have a loyalty program where you can earn points for every purchase. These points can be redeemed for discounts on future orders. Please visit our website to learn more and join the program.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 16}),\n",
       "  1.48043692111969),\n",
       " (Document(page_content='Question: What should I do if my discount code is not working? \\n Answer: If your discount code is not working, please double-check the terms and conditions associated with the code. If the issue persists, contact our customer support team for assistance.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 29}),\n",
       "  1.587053656578064)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How can I open an account?\"\n",
    "vectordb.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1f8cd",
   "metadata": {},
   "source": [
    "## Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dda1f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09524382",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Stuff Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36817e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=local_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b90cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "\n",
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(\"Answer:\")\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('Reference:')\n",
    "    for i, src_doc in enumerate(llm_response[\"source_documents\"]):\n",
    "        print(f'FAQ #{src_doc.metadata[\"seq_num\"]}:')\n",
    "        print(src_doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9938310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full example\n",
    "def get_answer(query):\n",
    "    llm_response = qa_chain(query)\n",
    "    process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89ebb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " To request a refund, you must have a receipt or proof of purchase. If you don't have a receipt, contact our\n",
      "customer support team for assistance. Refunds are typically processed within 10-14 business days after we\n",
      "receive your return.\n",
      "Reference:\n",
      "FAQ #33:\n",
      "Question: Can I return a product without a receipt? \n",
      " Answer: A receipt or proof of purchase is usually required for returns. Please refer to our return policy or contact our customer support team for assistance.\n",
      "\n",
      "FAQ #61:\n",
      "Question: Can I return a product if I no longer have the original receipt? \n",
      " Answer: While a receipt is preferred for returns, we may be able to assist you without it. Please contact our customer support team for further guidance.\n",
      "\n",
      "FAQ #4:\n",
      "Question: What is your return policy? \n",
      " Answer: Our return policy allows you to return products within 30 days of purchase for a full refund, provided they are in their original condition and packaging. Please refer to our Returns page for detailed instructions.\n",
      "\n",
      "FAQ #64:\n",
      "Question: Can I return a product if it was a clearance or final sale item? \n",
      " Answer: Clearance or final sale items are typically non-returnable and non-refundable. Please review the product description or contact our customer support team for more information.\n",
      "\n",
      "FAQ #49:\n",
      "Question: Can I return a product if it was purchased as a gift? \n",
      " Answer: Yes, you can return a product purchased as a gift. However, refunds will typically be issued to the original payment method used for the purchase.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  3017.18 ms\n",
      "llama_print_timings:      sample time =    23.57 ms /    57 runs   (    0.41 ms per token)\n",
      "llama_print_timings: prompt eval time =  3017.08 ms /   341 tokens (    8.85 ms per token)\n",
      "llama_print_timings:        eval time =  8270.14 ms /    56 runs   (  147.68 ms per token)\n",
      "llama_print_timings:       total time = 11404.08 ms\n"
     ]
    }
   ],
   "source": [
    "get_answer(\"What are the conditions for requesting a refund? Do I need to keep the receipt?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "830db63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Question: Can I return a product without a receipt? \\n Answer: A receipt or proof of purchase is usually required for returns. Please refer to our return policy or contact our customer support team for assistance.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 33}),\n",
       "  0.7929237484931946),\n",
       " (Document(page_content='Question: Can I return a product if I no longer have the original receipt? \\n Answer: While a receipt is preferred for returns, we may be able to assist you without it. Please contact our customer support team for further guidance.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 61}),\n",
       "  0.8628055453300476),\n",
       " (Document(page_content='Question: What is your return policy? \\n Answer: Our return policy allows you to return products within 30 days of purchase for a full refund, provided they are in their original condition and packaging. Please refer to our Returns page for detailed instructions.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 4}),\n",
       "  1.0256723165512085),\n",
       " (Document(page_content='Question: Can I return a product if it was a clearance or final sale item? \\n Answer: Clearance or final sale items are typically non-returnable and non-refundable. Please review the product description or contact our customer support team for more information.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 64}),\n",
       "  1.1272557973861694)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the conditions for requesting a refund? Do I need to keep the receipt?\" \n",
    "vectordb.similarity_search_with_score(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "732aef2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "{context}\n",
      "\n",
      "Question: {question}\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deb5ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To open an account, please visit our website and click on the 'Sign Up' button located on the top right corner of the homepage. From there, you will be prompted to enter your personal and business information, as well as your payment details. Once you have completed the registration process, you will receive a confirmation email to activate your account."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2952.18 ms\n",
      "llama_print_timings:      sample time =    37.51 ms /    74 runs   (    0.51 ms per token)\n",
      "llama_print_timings: prompt eval time =  3160.42 ms /   310 tokens (   10.19 ms per token)\n",
      "llama_print_timings:        eval time = 11416.28 ms /    73 runs   (  156.39 ms per token)\n",
      "llama_print_timings:       total time = 14830.66 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How can I open an account?',\n",
       " 'result': \" To open an account, please visit our website and click on the 'Sign Up' button located on the top right corner of the homepage. From there, you will be prompted to enter your personal and business information, as well as your payment details. Once you have completed the registration process, you will receive a confirmation email to activate your account.\",\n",
       " 'source_documents': [Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\\n\", metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 1}),\n",
       "  Document(page_content='Question: Can I order without creating an account? \\n Answer: Yes, you can place an order as a guest without creating an account. However, creating an account offers benefits such as order tracking and easier future purchases.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 17}),\n",
       "  Document(page_content='Question: Do you have a loyalty program? \\n Answer: Yes, we have a loyalty program where you can earn points for every purchase. These points can be redeemed for discounts on future orders. Please visit our website to learn more and join the program.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 16}),\n",
       "  Document(page_content='Question: What should I do if my discount code is not working? \\n Answer: If your discount code is not working, please double-check the terms and conditions associated with the code. If the issue persists, contact our customer support team for assistance.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 29}),\n",
       "  Document(page_content='Question: What payment methods do you accept? \\n Answer: We accept major credit cards, debit cards, and PayPal as payment methods for online orders.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 2})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response = qa_chain(query)\n",
    "llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf48caa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Refine chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3882889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_refine_chain = RetrievalQA.from_chain_type(\n",
    "    llm=local_llm, \n",
    "                                  chain_type=\"refine\", \n",
    "                                  retriever=retriever,\n",
    "                                              verbose=True,\n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4eee7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1892.35 ms\n",
      "llama_print_timings:      sample time =    14.55 ms /    34 runs   (    0.43 ms per token)\n",
      "llama_print_timings: prompt eval time =  1892.29 ms /    82 tokens (   23.08 ms per token)\n",
      "llama_print_timings:        eval time =  4695.60 ms /    33 runs   (  142.29 ms per token)\n",
      "llama_print_timings:       total time =  6655.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1892.35 ms\n",
      "llama_print_timings:      sample time =    35.27 ms /    85 runs   (    0.41 ms per token)\n",
      "llama_print_timings: prompt eval time =  1423.71 ms /   160 tokens (    8.90 ms per token)\n",
      "llama_print_timings:        eval time = 12018.94 ms /    84 runs   (  143.08 ms per token)\n",
      "llama_print_timings:       total time = 13629.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1892.35 ms\n",
      "llama_print_timings:      sample time =    58.16 ms /   142 runs   (    0.41 ms per token)\n",
      "llama_print_timings: prompt eval time =  1497.90 ms /   202 tokens (    7.42 ms per token)\n",
      "llama_print_timings:        eval time = 20907.67 ms /   141 runs   (  148.28 ms per token)\n",
      "llama_print_timings:       total time = 22897.98 ms\n"
     ]
    }
   ],
   "source": [
    "llm_response = qa_refine_chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d51ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'How can I open an account?',\n",
       " 'result': \" \\n------------\\nQuestion: How can I open an account and also sign up for your loyalty program?\\n Answer: To open an account and sign up for our loyalty program, click on the 'Sign Up' button on the top right corner of our website. During the registration process, you will have the option to join our loyalty program. Alternatively, you can also sign up through the 'Order as a Guest' option during checkout, but we recommend creating an account for easier future purchases and order tracking benefits. Once you have completed the registration process, you will be able to earn points for every purchase that can be redeemed for discounts on future orders.\",\n",
       " 'source_documents': [Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\\n\", metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 1}),\n",
       "  Document(page_content='Question: Can I order without creating an account? \\n Answer: Yes, you can place an order as a guest without creating an account. However, creating an account offers benefits such as order tracking and easier future purchases.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 17}),\n",
       "  Document(page_content='Question: Do you have a loyalty program? \\n Answer: Yes, we have a loyalty program where you can earn points for every purchase. These points can be redeemed for discounts on future orders. Please visit our website to learn more and join the program.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 16})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204c6fa",
   "metadata": {},
   "source": [
    "## Alternative version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbb9188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "        llm=local_llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever, \n",
    "        return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "710dd762",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  4275.01 ms\n",
      "llama_print_timings:      sample time =    13.50 ms /    32 runs   (    0.42 ms per token)\n",
      "llama_print_timings: prompt eval time =   832.51 ms /    11 tokens (   75.68 ms per token)\n",
      "llama_print_timings:        eval time =  6013.54 ms /    31 runs   (  193.99 ms per token)\n",
      "llama_print_timings:       total time = 13634.38 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How can I open an account?',\n",
       " 'answer': \" To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\",\n",
       " 'sources': '',\n",
       " 'source_documents': [Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\\n\", metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 1}),\n",
       "  Document(page_content='Question: Can I order without creating an account? \\n Answer: Yes, you can place an order as a guest without creating an account. However, creating an account offers benefits such as order tracking and easier future purchases.\\n', metadata={'source': '/home/tamizh/projects/llm-doc-retrieval-and-qa/data/faq_dataset.json', 'seq_num': 17})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "722cea9d-6a7e-43bd-8536-0aa2afa65cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, page_content):\n",
    "        self.page_content = page_content\n",
    "\n",
    "def dummy_chain(query):\n",
    "    return {\n",
    "        'question': 'How can I open an account?', \n",
    "        'answer': \" To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\", \n",
    "        'sources': '', \n",
    "        'source_documents': [\n",
    "            Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account\"), \n",
    "            Document(page_content=\"Question: Do you have a loyalty program? \\n Answer: No, we have royalty program\"), \n",
    "        ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae74156b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3781.58 ms\n",
      "llama_print_timings:      sample time =    24.05 ms /    54 runs   (    0.45 ms per token)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token)\n",
      "llama_print_timings:        eval time = 11029.36 ms /    54 runs   (  204.25 ms per token)\n",
      "llama_print_timings:       total time = 11288.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3781.58 ms\n",
      "llama_print_timings:      sample time =     5.15 ms /    12 runs   (    0.43 ms per token)\n",
      "llama_print_timings: prompt eval time =  3530.32 ms /   302 tokens (   11.69 ms per token)\n",
      "llama_print_timings:        eval time =  2125.30 ms /    11 runs   (  193.21 ms per token)\n",
      "llama_print_timings:       total time =  5896.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3781.58 ms\n",
      "llama_print_timings:      sample time =    41.39 ms /    89 runs   (    0.47 ms per token)\n",
      "llama_print_timings: prompt eval time =  3424.52 ms /   308 tokens (   11.12 ms per token)\n",
      "llama_print_timings:        eval time = 17230.27 ms /    88 runs   (  195.80 ms per token)\n",
      "llama_print_timings:       total time = 21320.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3781.58 ms\n",
      "llama_print_timings:      sample time =     6.15 ms /    14 runs   (    0.44 ms per token)\n",
      "llama_print_timings: prompt eval time =  3188.97 ms /   271 tokens (   11.77 ms per token)\n",
      "llama_print_timings:        eval time =  2551.93 ms /    13 runs   (  196.30 ms per token)\n",
      "llama_print_timings:       total time =  6035.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  3781.58 ms\n",
      "llama_print_timings:      sample time =     4.00 ms /     9 runs   (    0.44 ms per token)\n",
      "llama_print_timings: prompt eval time =  3361.52 ms /   290 tokens (   11.59 ms per token)\n",
      "llama_print_timings:        eval time =  1602.96 ms /     8 runs   (  200.37 ms per token)\n",
      "llama_print_timings:       total time =  5152.44 ms\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "\n",
    "try:\n",
    "    faq_bot.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "css = \"\"\" \n",
    "    #output_container_0 div.eta-bar {\n",
    "    display: none !important; transform: none !important;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def format_answer(answer_dict):\n",
    "    sources = [(doc.page_content.split(\"\\n\")[0].replace(\"Question: \", \"\").strip(),  \n",
    "                  doc.page_content.split(\"\\n\")[1].replace(\"Answer: \", \"\").strip())\n",
    "                  for doc in answer_dict[\"source_documents\"]]\n",
    "    answer = answer_dict[\"answer\"]\n",
    "    references = \"## References\\n\" + \"\\n\\n\".join(f\"**{q}**\\n\\n > {a}\" for q, a in sources)\n",
    "    return (answer, references)\n",
    "    \n",
    "def generate_response(query):\n",
    "    generated_text = chain(query)\n",
    "    answer, references = format_answer(generated_text)\n",
    "    return {answer_block: answer, references_block: references}\n",
    "\n",
    "with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as faq_bot:\n",
    "    gr.Markdown(\"Talk to our FAQ bot\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            answer_block = gr.Textbox(label=\"Answers\", lines=2)\n",
    "        with gr.Column():\n",
    "            references_block = gr.Markdown(\"## References\")\n",
    "    inputs = gr.Textbox(label=\"Type your question here\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Ask\")\n",
    "        clear_btn = gr.ClearButton([inputs, answer_block, references_block])\n",
    "        \n",
    "    submit_btn.click(fn=generate_response, \n",
    "                     inputs=inputs, \n",
    "                     outputs=[answer_block, references_block],\n",
    "                     show_progress=False)\n",
    "    examples_block = gr.Examples(\n",
    "        [\"How can I create an account?\", \n",
    "         \"What is the return policy?\",\n",
    "         \"How can I contact customer support?\"], inputs)\n",
    "    \n",
    "faq_bot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "730bb1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamizh/miniconda3/envs/langchain-llm/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/tamizh/miniconda3/envs/langchain-llm/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/tamizh/miniconda3/envs/langchain-llm/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/tmp/ipykernel_5654/64917599.py:48: UserWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  interface = gr.Interface(\n",
      "/tmp/ipykernel_5654/64917599.py:48: UserWarning: `show_input` parameter is deprecated, and it has no effect\n",
      "  interface = gr.Interface(\n",
      "/tmp/ipykernel_5654/64917599.py:48: UserWarning: `show_output` parameter is deprecated, and it has no effect\n",
      "  interface = gr.Interface(\n",
      "/tmp/ipykernel_5654/64917599.py:48: UserWarning: You have unused kwarg parameters in Interface, please remove them: {'progress_bar': False, 'placeholder': 'Ask your question'}\n",
      "  interface = gr.Interface(\n",
      "/home/tamizh/miniconda3/envs/langchain-llm/lib/python3.10/site-packages/gradio/interface.py:326: UserWarning: The `allow_flagging` parameter in `Interface` nowtakes a string value ('auto', 'manual', or 'never'), not a boolean. Setting parameter to: 'never'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "import gradio as gr\n",
    "\n",
    "if interface:\n",
    "    interface.close()\n",
    "\n",
    "\n",
    "# Define Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=generate_response,\n",
    "    inputs=gr.inputs.Textbox(label=\"Type your message here...\"),\n",
    "    outputs=gr.outputs.HTML(label=\"\"),\n",
    "    title=\"LangChain Chatbot\",\n",
    "    description=\"Talk to the LangChain chatbot!\",\n",
    "    layout=\"vertical\",\n",
    "    examples=[\n",
    "        [\"How can I return a product?\"],\n",
    "        [\"What is the return policy?\"],\n",
    "        [\"How can I contact customer support?\"],\n",
    "    ],\n",
    "    allow_flagging=False,\n",
    "    show_input=True,\n",
    "    show_output=True,\n",
    "    progress_bar=False,\n",
    "    placeholder=\"Ask your question\",\n",
    ")\n",
    "\n",
    "interface.css  = \"\"\"\n",
    "    \n",
    "    #output_container_0 div.eta-bar {\n",
    "    display: none !important; transform: none !important;\n",
    "    }\n",
    "   \"\"\"\n",
    "   \n",
    "\n",
    "# Launch interface\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0734aebc-2766-4b84-9564-38442989b471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, page_content):\n",
    "        self.page_content = page_content\n",
    "\n",
    "def dummy_chain(query):\n",
    "    return {\n",
    "        'question': 'How can I open an account?', \n",
    "        'answer': \" To create an account, click on the 'Sign Up' button on the top right corner of our website and follow the instructions to complete the registration process.\", \n",
    "        'sources': '', \n",
    "        'source_documents': [\n",
    "            Document(page_content=\"Question: How can I create an account? \\n Answer: To create an account\"), \n",
    "            Document(page_content=\"Question: Do you have a loyalty program? \\n Answer: No, we have royalty program\"), \n",
    "        ]}\n",
    "\n",
    "def format_answer(answer_dict):\n",
    "    # Extract answer and references from dictionary\n",
    "    answer = answer_dict[\"answer\"]\n",
    "    \n",
    "    references = [(doc.page_content.split(\"\\n\")[0].replace(\"Question: \", \"\").strip(),  \n",
    "                  doc.page_content.split(\"\\n\")[1].replace(\"Answer: \", \"\").strip())\n",
    "                  for doc in answer_dict[\"source_documents\"]]\n",
    "\n",
    "    \n",
    "    # Create HTML containers for answer and references\n",
    "    answer_container = f\"<div style='background-color: #141414; padding: 10px'>{answer}</div>\"\n",
    "\n",
    "    references_container = \"\"\n",
    "    for (question, answer) in references:\n",
    "        references_container += f\"<div style='background-color: #040404; padding: 10px; margin-top: 10px'>{answer}</div>\"\n",
    "    \n",
    "    # Combine containers and return\n",
    "    return answer_container + references_container\n",
    "\n",
    "\n",
    "def generate_response(query):\n",
    "    generated_text = dummy_chain(query)\n",
    "    response = format_answer(generated_text)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1116ed-4a21-458f-a481-c756c108128a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aa797b-e023-460e-bde8-83c4e0692ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2cf85f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Backup\n",
    "import gradio as gr\n",
    "import random\n",
    "import time\n",
    "\n",
    "try:\n",
    "    faq_bot.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "css = \"\"\" \n",
    "    #output_container_0 div.eta-bar {\n",
    "    display: none !important; transform: none !important;\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "def format_answer(answer_dict):\n",
    "    answer = answer_dict[\"answer\"]\n",
    "    \n",
    "    sources = [(doc.page_content.split(\"\\n\")[0].replace(\"Question: \", \"\").strip(),  \n",
    "                  doc.page_content.split(\"\\n\")[1].replace(\"Answer: \", \"\").strip())\n",
    "                  for doc in answer_dict[\"source_documents\"]]\n",
    "\n",
    "    answer = f\"## {answer}\\n\"\n",
    "\n",
    "    references = \"## References\\n\"\n",
    "    for (question, answer) in sources:\n",
    "        references += f\"**{question}**\\n\\n\"\n",
    "        references += f\"> {answer}\\n\\n\"\n",
    "    return (answer, references)\n",
    "    \n",
    "def generate_response(query):\n",
    "    generated_text = dummy_chain(query)\n",
    "    answer, references = format_answer(generated_text)\n",
    "    return {answer_block: answer, references_block: references}\n",
    "\n",
    "with gr.Blocks(css=css, theme=gr.themes.Monochrome()) as faq_bot:\n",
    "    gr.Markdown(\"Talk to our FAQ bot\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            answer_block = gr.Textbox(label=\"Answers\", lines=2)\n",
    "        with gr.Column():\n",
    "            references_block = gr.Markdown(\"## References\")\n",
    "    inputs = gr.Textbox(label=\"Type your question here\")\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Ask\")\n",
    "        clear_btn = gr.ClearButton([inputs, answer_block, references_block])\n",
    "    submit_btn.click(fn=generate_response, \n",
    "                     inputs=inputs, \n",
    "                     outputs=[answer_block, references_block],\n",
    "                     show_progress=False)\n",
    "    gr.Examples(\n",
    "        [\n",
    "        [\"How can I return a product?\", \"How can I return a product?\"],\n",
    "        [\"What is the return policy?\", \"What is the return policy?\"],\n",
    "        [\"How can I contact customer support?\", \"How can I contact customer support?\"],\n",
    "        ], inputs)\n",
    "    \n",
    "faq_bot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85573c-665b-41b6-bb6c-b8bf09cff8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain-llm] *",
   "language": "python",
   "name": "conda-env-langchain-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
